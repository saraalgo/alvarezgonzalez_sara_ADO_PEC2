---
title: "PEC2 ADO"
author: "Sara Álvarez González"
date: "Mayo de 2020"
output: 
    html_document:
      toc: true
      toc_float: true
    pdf_document:

lang: es-ES
---
<div class=text-justify>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r paquetes, include=FALSE}
setwd("C:/Users/Sara/Desktop/alvarezgonzalez_sara_ADO_PEC2")
library(dplyr)
library(tweeDEseqCountData)
library(tweeDEseq)
library(edgeR)
```
***
## 0.Extraer datos

Cargamos los datos que nos dan:

```{r}
counts = read.csv("counts.csv",header=T,sep = ";")
target = read.csv("targets.csv",header=T,sep = ",")
```

Primero extraer las que son del mismo grupo a variables separadas para después seleccionar 10 de cada uno de los grupos:

```{r}
NIT <- subset(target,grepl("^(NIT)", target$Group))
SFI <- subset(target,grepl("^(SFI)", target$Group))
ELI <- subset(target,grepl("^(ELI)", target$Group))

set.seed(12)

NIT_10 <- sample_n(NIT, 10)
SFI_10 <- sample_n(SFI, 10)
ELI_10 <- sample_n(ELI, 10)


columnas <- rbind(NIT_10,SFI_10,ELI_10)
grupos <- as.factor(columnas$Group)
```

Finalmente extraer con las variables anteriores los datos con los que se va a trabajar:

```{r}
Grupo1 <- counts[,NIT_10$Sample_Name]
Grupo2 <- counts[,SFI_10$Sample_Name]
Grupo3 <- counts[,ELI_10$Sample_Name]

datos <- cbind(Grupo1,Grupo2,Grupo3)

#write.csv(datos,"datos.csv", row.names = FALSE)
```


## 1. Normalización y filtrado

En primer lugar, debido a que ya se ha filtrado seleccionando aleatoriamente solo las columnas con las que vamos a trabajar, llevaremos a cabo un normalizado **TMM**, no es necesario definirlo con la función *normalizeCounts*, ya que por defecto es la que hace:

```{r}
datos_f <- normalizeCounts(datos)
maPlot(datos_f[,1], datos_f[,2],
       pch=19, cex=.5, ylim=c(-8,8), 
       allCol="darkgrey", lowess=TRUE)
grid(col="black")
title("normalización TMM")
```



</div>